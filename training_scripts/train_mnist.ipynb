{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ypeikes18/Projects/diffusion\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "os.chdir(\"..\")\n",
    "print(os.getcwd())\n",
    "sys.path.append(\"\")\n",
    "\n",
    "import torch as t\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from time_step_sampler import TimeStepSampler\n",
    "import torch.nn as nn\n",
    "from diffusion import Diffusion\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "DEVICE = t.device(\"cuda\" if t.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nums_to_one_hot(nums: t.Tensor, d_input: int) -> t.Tensor:\n",
    "    \"\"\"\n",
    "    :param nums: (batch_size,)\n",
    "    :param d_input: int\n",
    "    :return: (batch_size, d_input)\n",
    "    \"\"\"\n",
    "    one_hots = t.zeros(nums.shape[0], d_input)\n",
    "    one_hots.scatter_(1, nums.long().unsqueeze(1), 1)\n",
    "    return one_hots\n",
    "\n",
    "# Wrote this for MNIST to turn 1 hot encoded labels into guidance embeddings\n",
    "class MNISTGuidanceEmbedder(nn.Module):\n",
    "    def __init__(self, d_embedding: int) -> None:\n",
    "        super().__init__()\n",
    "        self.d_input = 10\n",
    "        self.d_embedding = d_embedding\n",
    "        self.projection = nn.Linear(10, d_embedding)\n",
    "        self.l2 = nn.Linear(d_embedding, d_embedding)\n",
    "        self.relu = nn.ReLU()\n",
    "        # for classifier free guidance\n",
    "        self.null_guidance = nn.Parameter(t.zeros(self.d_input), requires_grad=True)\n",
    "\n",
    "    def forward(self, guidance: t.Tensor, guidance_free_prob: float=0.1) -> t.Tensor:\n",
    "        \"\"\"\n",
    "        :param guidance: (batch_size, d_guidance)\n",
    "        :param guidance_free_prob: float\n",
    "        :return: (batch_size, d_embedding)\n",
    "        \"\"\"\n",
    "        # randomly choose indices to replace batch samples with null guidance\n",
    "        null_guidance_indices = t.rand(guidance.shape[0]) < guidance_free_prob\n",
    "        guidance[null_guidance_indices] = self.null_guidance\n",
    "        guidance = self.projection(guidance)\n",
    "        guidance = self.relu(guidance)\n",
    "        guidance = self.l2(guidance)\n",
    "        return guidance\n",
    "\n",
    "\n",
    "def train(model,\n",
    "guidance_embedder: MNISTGuidanceEmbedder,\n",
    "data: Dataset, \n",
    "epochs: int=1, \n",
    "batch_size: int=64, \n",
    "print_intervals: int=1, \n",
    "debug: bool=False, \n",
    "batches: int=float('inf'), \n",
    "time_steps: int=None, \n",
    "lr: float=1e-4,\n",
    "use_importance_sampling: bool=True,\n",
    "guidance_free_prob: float=0.1):\n",
    "    data = DataLoader(data, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    model = model.to(DEVICE)\n",
    "    guidance_embedder = MNISTGuidanceEmbedder(model.backbone.d_model).to(DEVICE)\n",
    "\n",
    "    optimizer = t.optim.Adam(\n",
    "        list(model.parameters()) + list(guidance_embedder.parameters()),\n",
    "        lr=lr\n",
    "    )\n",
    "    time_step_sampler = TimeStepSampler(model.training_time_steps, use_importance_sampling=use_importance_sampling)\n",
    "    model.losses = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for i ,(batch, labels) in enumerate(data):\n",
    "            \n",
    "            batch, labels = batch.to(DEVICE), labels.to(DEVICE)\n",
    "\n",
    "            if i >= batches:\n",
    "                break\n",
    "\n",
    "            time_steps = time_step_sampler.sample_time_steps(batch.shape[0]).to(DEVICE)\n",
    "            one_hot_labels = nums_to_one_hot(labels.long(), 10)\n",
    "            guidance = guidance_embedder(one_hot_labels, guidance_free_prob)\n",
    "\n",
    "            noisy_data = model.forward_process(batch, time_steps)\n",
    "            predicted_batch = model(noisy_data, time_steps, guidance=guidance)\n",
    "            batch_losses = t.nn.MSELoss(reduction='none')(predicted_batch, batch).mean(dim=[1, 2, 3])\n",
    "            loss = batch_losses.mean()\n",
    "            \n",
    "            if use_importance_sampling:\n",
    "                time_step_sampler.update_losses(time_steps.detach().numpy(), batch_losses.detach().numpy())\n",
    "            \n",
    "            model.losses.append(loss.detach().numpy())\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if i % print_intervals == 0:\n",
    "                print(f\"Epoch [{epoch+1}/{epochs}], Batch [{i+1}/{batches}], Loss: {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Batch [1/inf], Loss: 0.0650\n",
      "Epoch [1/2], Batch [6/inf], Loss: 0.0667\n",
      "Epoch [1/2], Batch [11/inf], Loss: 0.0595\n",
      "Epoch [1/2], Batch [16/inf], Loss: 0.0595\n",
      "Epoch [1/2], Batch [21/inf], Loss: 0.0579\n",
      "Epoch [1/2], Batch [26/inf], Loss: 0.0599\n",
      "Epoch [1/2], Batch [31/inf], Loss: 0.0591\n",
      "Epoch [1/2], Batch [36/inf], Loss: 0.0584\n",
      "Epoch [1/2], Batch [41/inf], Loss: 0.0574\n",
      "Epoch [1/2], Batch [46/inf], Loss: 0.0596\n",
      "Epoch [1/2], Batch [51/inf], Loss: 0.0601\n",
      "Epoch [1/2], Batch [56/inf], Loss: 0.0591\n",
      "Epoch [1/2], Batch [61/inf], Loss: 0.0593\n",
      "Epoch [1/2], Batch [66/inf], Loss: 0.0583\n",
      "Epoch [1/2], Batch [71/inf], Loss: 0.0572\n",
      "Epoch [1/2], Batch [76/inf], Loss: 0.0554\n",
      "Epoch [1/2], Batch [81/inf], Loss: 0.0572\n",
      "Epoch [1/2], Batch [86/inf], Loss: 0.0534\n",
      "Epoch [1/2], Batch [91/inf], Loss: 0.0548\n",
      "Epoch [1/2], Batch [96/inf], Loss: 0.0563\n",
      "Epoch [1/2], Batch [101/inf], Loss: 0.0530\n",
      "Epoch [1/2], Batch [106/inf], Loss: 0.0531\n",
      "Epoch [1/2], Batch [111/inf], Loss: 0.0538\n",
      "Epoch [1/2], Batch [116/inf], Loss: 0.0533\n",
      "Epoch [1/2], Batch [121/inf], Loss: 0.0480\n",
      "Epoch [1/2], Batch [126/inf], Loss: 0.0553\n",
      "Epoch [1/2], Batch [131/inf], Loss: 0.0515\n",
      "Epoch [1/2], Batch [136/inf], Loss: 0.0531\n",
      "Epoch [1/2], Batch [141/inf], Loss: 0.0540\n",
      "Epoch [1/2], Batch [146/inf], Loss: 0.0572\n",
      "Epoch [1/2], Batch [151/inf], Loss: 0.0533\n",
      "Epoch [1/2], Batch [156/inf], Loss: 0.0508\n",
      "Epoch [1/2], Batch [161/inf], Loss: 0.0541\n",
      "Epoch [1/2], Batch [166/inf], Loss: 0.0545\n",
      "Epoch [1/2], Batch [171/inf], Loss: 0.0509\n",
      "Epoch [1/2], Batch [176/inf], Loss: 0.0593\n",
      "Epoch [1/2], Batch [181/inf], Loss: 0.0546\n",
      "Epoch [1/2], Batch [186/inf], Loss: 0.0518\n",
      "Epoch [1/2], Batch [191/inf], Loss: 0.0495\n",
      "Epoch [1/2], Batch [196/inf], Loss: 0.0526\n",
      "Epoch [1/2], Batch [201/inf], Loss: 0.0544\n",
      "Epoch [1/2], Batch [206/inf], Loss: 0.0552\n",
      "Epoch [1/2], Batch [211/inf], Loss: 0.0552\n",
      "Epoch [1/2], Batch [216/inf], Loss: 0.0516\n",
      "Epoch [1/2], Batch [221/inf], Loss: 0.0559\n",
      "Epoch [1/2], Batch [226/inf], Loss: 0.0499\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(t\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweights/model_with_guidance_2.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m     15\u001b[0m embedder\u001b[38;5;241m.\u001b[39mload_state_dict(t\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweights/guidance_embedder_2.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m---> 16\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43membedder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_intervals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdebug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2e-5\u001b[39;49m\n\u001b[1;32m     20\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m t\u001b[38;5;241m.\u001b[39msave(model\u001b[38;5;241m.\u001b[39mstate_dict(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweights/model_with_guidance_2.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     23\u001b[0m t\u001b[38;5;241m.\u001b[39msave(embedder\u001b[38;5;241m.\u001b[39mstate_dict(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweights/guidance_embedder_2.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[7], line 85\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, guidance_embedder, data, epochs, batch_size, print_intervals, debug, batches, time_steps, lr, use_importance_sampling, guidance_free_prob)\u001b[0m\n\u001b[1;32m     82\u001b[0m model\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m     84\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 85\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m%\u001b[39m print_intervals \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/Projects/diffusion/venv/lib/python3.12/site-packages/torch/_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    524\u001b[0m     )\n\u001b[0;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/diffusion/venv/lib/python3.12/site-packages/torch/autograd/__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/diffusion/venv/lib/python3.12/site-packages/torch/autograd/graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    data = torchvision.datasets.MNIST(\n",
    "        root=\"mnist/\", train=True, download=True, transform=torchvision.transforms.ToTensor()\n",
    "    )\n",
    "\n",
    "\n",
    "    model = Diffusion(\n",
    "        input_shape=(1, 28, 28), \n",
    "        use_importance_sampling=True, \n",
    "        training_time_steps=500, \n",
    "    )\n",
    "\n",
    "    embedder = MNISTGuidanceEmbedder(model.backbone.d_model)\n",
    "    model.load_state_dict(t.load(\"weights/model_with_guidance_2.pth\"))\n",
    "    embedder.load_state_dict(t.load(\"weights/guidance_embedder_2.pth\"))\n",
    "    train(\n",
    "        model,embedder, data, epochs=2, \n",
    "        batch_size=64, print_intervals=5, \n",
    "        debug=True, lr=2e-5\n",
    "    )\n",
    "\n",
    "    t.save(model.state_dict(), \"weights/model_with_guidance_2.pth\")\n",
    "    t.save(embedder.state_dict(), \"weights/guidance_embedder_2.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
